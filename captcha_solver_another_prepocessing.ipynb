{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f755c0-2261-41fa-ad02-55b6cb6108ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import string\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397552f6-ed49-4468-b027-ac661dff534e",
   "metadata": {},
   "source": [
    "# Create by index of symbol folder in the train and test folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed3b0854-2f43-42d5-8fa8-98bb9d148232",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_SYMBOLS = string.ascii_uppercase# + string.digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "949e633c-760f-4f60-8b72-95fa1daf098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mapper = {}\n",
    "for index, value in enumerate(ALL_SYMBOLS):\n",
    "    target_mapper[value] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8155438-8f0f-484a-a7a7-08cd682b8ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_mapper[\"A\"], target_mapper[\"Z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8779b940-1434-4f4c-aa52-80c85fa68de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0,\n",
       " 'B': 1,\n",
       " 'C': 2,\n",
       " 'D': 3,\n",
       " 'E': 4,\n",
       " 'F': 5,\n",
       " 'G': 6,\n",
       " 'H': 7,\n",
       " 'I': 8,\n",
       " 'J': 9,\n",
       " 'K': 10,\n",
       " 'L': 11,\n",
       " 'M': 12,\n",
       " 'N': 13,\n",
       " 'O': 14,\n",
       " 'P': 15,\n",
       " 'Q': 16,\n",
       " 'R': 17,\n",
       " 'S': 18,\n",
       " 'T': 19,\n",
       " 'U': 20,\n",
       " 'V': 21,\n",
       " 'W': 22,\n",
       " 'X': 23,\n",
       " 'Y': 24,\n",
       " 'Z': 25}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79d80beb-9302-47d1-99cb-11ecc676ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f51dcb97-4037-4511-8979-92e1527bda22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = os.path.join(parent_dir, \"training_data\")\n",
    "test_data = os.path.join(parent_dir, \"test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc121487-3b70-4149-a940-d1976949e279",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\projects\\captcha_solver\\training_data\\0 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\0 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\1 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\1 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\2 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\2 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\3 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\3 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\4 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\4 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\5 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\5 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\6 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\6 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\7 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\7 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\8 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\8 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\9 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\9 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\10 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\10 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\11 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\11 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\12 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\12 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\13 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\13 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\14 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\14 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\15 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\15 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\16 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\16 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\17 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\17 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\18 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\18 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\19 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\19 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\20 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\20 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\21 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\21 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\22 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\22 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\23 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\23 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\24 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\24 already exists\n",
      "E:\\projects\\captcha_solver\\training_data\\25 already exists\n",
      "E:\\projects\\captcha_solver\\test_data\\25 already exists\n"
     ]
    }
   ],
   "source": [
    "for symbol in target_mapper.keys():\n",
    "    path = os.path.join(train_data, str(target_mapper[symbol]))\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except:\n",
    "        print(f\"{path} already exists\")\n",
    "\n",
    "    path = os.path.join(test_data, str(target_mapper[symbol]))\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except:\n",
    "        print(f\"{path} already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad60718-7bdd-4a7f-a967-fa04b56c719d",
   "metadata": {},
   "source": [
    "# Split every image, generated by captcha into the either training folder or testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "320aadaf-e9eb-4389-993a-303d5d00cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import random\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65abf0c9-9661-4077-9b9c-66d8326a1c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_captchas = glob(\"captcha_images/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "623dc54b-a7c5-4c5d-b8bc-f41d80d5c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleList = [\"training_data\", \"test_data\"]\n",
    " \n",
    "randomList = random.choices(sampleList, weights=(80, 20), k=len(all_captchas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54b28bb8-818d-48bc-a8b3-48e383cbd1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min(val1, val2):\n",
    "    res = val2\n",
    "    if val1 < val2:\n",
    "        res = val1\n",
    "    return res\n",
    "\n",
    "def get_max(val1, val2):\n",
    "    res = val2\n",
    "    if val1 > val2:\n",
    "        res = val1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "486709c6-e2bf-4649-adb7-50011814701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corners(contour):\n",
    "    min_x = contour[0][0][0]\n",
    "    min_y = contour[0][0][1]\n",
    "    max_x = contour[0][0][0]\n",
    "    max_y = contour[0][0][1]\n",
    "    for point in contour:\n",
    "        x, y = point[0]\n",
    "        min_x = get_min(min_x, x)\n",
    "        min_y = get_min(min_y, y)\n",
    "        max_x = get_max(max_x, x)\n",
    "        max_y = get_max(max_y, y)\n",
    "\n",
    "    return ((min_x, min_y), (max_x, max_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec91c696-6c0c-4ffe-a27b-090e4907c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_contour(boxB, boxA):\n",
    "    startA, endA = boxA\n",
    "    startB, endB = boxB\n",
    "    start_lower = (startA[0] <= startB[0]) and (startA[1] <= startB[1])\n",
    "    end_bigger = (endA[0] >= endB[0]) and (endA[1] >= endB[1])\n",
    "    return start_lower and end_bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c220bb32-5977-4462-b2cc-c881789e893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_inner_contour(boxes):\n",
    "    result = []\n",
    "    for i in range(len(boxes)):\n",
    "        flag = False\n",
    "        for j in range(len(boxes)):\n",
    "            if j != i:\n",
    "                if inner_contour(boxes[i], boxes[j]):\n",
    "                    flag = True\n",
    "        if not flag:\n",
    "            result.append(boxes[i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9670b409-e928-4ac3-8982-416e90453e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_square(start, end):\n",
    "    length = end[0] - start[0]\n",
    "    height = end[1] - start[1]\n",
    "    return length * height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0935067f-03cc-44f2-a724-6670fc75c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rectangles(boxes):\n",
    "    boxes = list(sorted(boxes, key=lambda x: x[1][0] - x[0][0]))\n",
    "    box_to_split = boxes.pop()\n",
    "    start, end = box_to_split\n",
    "    width = end[0] - start[0]\n",
    "    height = end[1] - start[1]\n",
    "    box1 = ((start[0], start[1]), (start[0] + (width // 2), end[1]))\n",
    "    box2 = ((start[0] + (width // 2), start[1]), (end[0], end[1]))\n",
    "    boxes.append(box1)\n",
    "    boxes.append(box2)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d730065-2efa-4f36-9178-9f1e2d4ef01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_14px(box):\n",
    "    start, end = box\n",
    "    start = (start[0] - 3, start[1] - 3)\n",
    "    end = (end[0] + 3, end[1] + 3)\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ad0e7a3b-898f-43c9-8c23-466fafd16814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_rectangle(rectangle, expansion_factor):\n",
    "    \"\"\"\n",
    "    Expand the coordinates of a rectangle by a given expansion factor.\n",
    "\n",
    "    Args:\n",
    "    rectangle (tuple): Tuple containing (x_min, y_min, x_max, y_max) coordinates of the rectangle.\n",
    "    expansion_factor (float): Factor by which to expand the rectangle.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Expanded rectangle coordinates in the format (x_min_expanded, y_min_expanded, x_max_expanded, y_max_expanded).\n",
    "    \"\"\"\n",
    "    start, end = rectangle\n",
    "    x_min, y_min = start\n",
    "    x_max, y_max = end\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    x_center = (x_min + x_max) / 2\n",
    "    y_center = (y_min + y_max) / 2\n",
    "\n",
    "    new_width = width * expansion_factor\n",
    "    new_height = height * expansion_factor\n",
    "\n",
    "    x_min_expanded = max(int(x_center - new_width / 2), 0)\n",
    "    y_min_expanded = max(int(y_center - new_height / 2), 0)\n",
    "    x_max_expanded = int(x_center + new_width / 2)\n",
    "    y_max_expanded = int(y_center + new_height / 2)\n",
    "\n",
    "    return ((x_min_expanded, y_min_expanded), (x_max_expanded, y_max_expanded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "51a87cfa-65d4-4396-9b32-c2c4aa030d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'captcha_images\\\\AFHL.png'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 65\n",
    "all_captchas[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "87b6f53b-fd28-4c2c-9e3c-5d4917fd3c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_symb = 0\n",
    "ccc = 0\n",
    "for idx in range(len(all_captchas)):\n",
    "    if randomList[idx]==\"training_data\":\n",
    "        path = train_data\n",
    "    else:\n",
    "        path = test_data\n",
    "        \n",
    "    img = cv.imread(all_captchas[idx])\n",
    "    threshold = 150\n",
    "    \n",
    "    # cv.imshow(\"\", img)\n",
    "    # cv.waitKey()\n",
    "    # cv.destroyAllWindows()\n",
    "    \n",
    "    # convert to grayscale\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    # blur\n",
    "    blur = cv.GaussianBlur(gray, (0, 0), sigmaX=33, sigmaY=33)\n",
    "    # divide\n",
    "    divide = cv.divide(gray, blur, scale=255)\n",
    "    # otsu threshold\n",
    "    thresh = cv.threshold(divide, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)[1] # \n",
    "    # apply morphology\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (4, 4))\n",
    "    morph = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    canny_output = cv.Canny(morph, threshold, threshold * 2)\n",
    "    canny_output_cp = canny_output.copy()\n",
    "    canny_output = cv.blur(canny_output, (3, 3))\n",
    "    \n",
    "    # cv.imshow(\"\", canny_output)\n",
    "    # cv.waitKey()\n",
    "    # cv.destroyAllWindows()\n",
    "    \n",
    "    contours, hierarchy = cv.findContours(canny_output, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    contours = [get_corners(i) for i in contours]\n",
    "    contours = filter_inner_contour(contours)\n",
    "    contours = sorted(contours, key=lambda x: get_square(*x), reverse=True)\n",
    "    contours = list(filter(lambda x: get_square(*x) > 400, contours))\n",
    "    if not contours:\n",
    "        ccc += 1\n",
    "        continue\n",
    "    while len(contours) < 4:\n",
    "        contours = split_rectangles(contours)\n",
    "    contours = sorted(contours, key=lambda x: x[0][0])\n",
    "    contours = [expand_rectangle(i, 1.5) for i in contours]\n",
    "    \n",
    "    symbols = re.search(r\"\\\\(\\w+)\\.\", all_captchas[idx]).group(1)\n",
    "    # drawing = np.zeros((canny_output.shape[0], canny_output.shape[1], 3), dtype=np.uint8)\n",
    "    for i in range(4):\n",
    "        color = (random.randint(0,256), random.randint(0,256), random.randint(0,256))\n",
    "        # morph = cv.rectangle(morph, contours[i][0], contours[i][1], color, 2)\n",
    "        # cv.drawContours(drawing, contours, i, color, 2, cv.LINE_8, hierarchy, 0)\n",
    "        curr_path = os.path.join(path, str(target_mapper[symbols[i]]))\n",
    "        curr_path = os.path.join(curr_path, \"{0:010d}.png\".format(curr_symb))\n",
    "        curr_symb += 1\n",
    "        crop_img = morph[contours[i][0][1]:contours[i][1][1], contours[i][0][0]:contours[i][1][0]]\n",
    "        # morph[contours[i][0][1]:contours[i][1][1], contours[i][0][0]:contours[i][1][0]]\n",
    "        cv.imwrite(curr_path, crop_img)\n",
    "        \n",
    "# cv.imshow(\"\", morph)\n",
    "# cv.waitKey()\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f75cc91-25e1-42bf-9877-223b060776cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.imshow(\"\", img)\n",
    "# cv.waitKey()\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cecce3f-ba78-42c4-a8c7-fc89ee18904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.imshow(\"\", morph)\n",
    "# cv.waitKey()\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1336e7-b4d2-455a-9d1e-071c31b71b67",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d775869b-7882-478c-b9aa-97015680c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, InputLayer, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.metrics import AUC\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1a5fed11-5f46-47a2-b557-f52b3371cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value= 145\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5f4b9dc2-84a2-4412-be78-89dae3f8f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(os.getcwd(), \"training_data\")\n",
    "test_path = os.path.join(os.getcwd(), \"test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8dca6774-2102-41b3-b140-4120125a1238",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up hyperparameters that will be used later\n",
    "hyper_dimension = 128\n",
    "hyper_batch_size = 512\n",
    "hyper_epochs = 100\n",
    "hyper_channels = 1\n",
    "hyper_mode = 'grayscale'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ae36eec8-0ce9-4e0f-b2c9-61e98ecc4ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate batches of image data (train, validation, and test) with data augmentation\n",
    "## Augmentation helps to lower variance of complex model\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0, \n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2, \n",
    "                                   horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9fe63ea4-8d80-416e-bce0-80f1c94bc78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33052 images belonging to 26 classes.\n",
      "Found 9052 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory = train_path, \n",
    "                                                    target_size = (hyper_dimension, hyper_dimension),\n",
    "                                                    batch_size = hyper_batch_size, \n",
    "                                                    color_mode = hyper_mode,\n",
    "                                                    class_mode = 'categorical',\n",
    "                                                    # classes = target_mapper.values(),\n",
    "                                                    seed = seed_value)\n",
    "test_generator = test_datagen.flow_from_directory(directory = test_path, \n",
    "                                                 target_size = (hyper_dimension, hyper_dimension),\n",
    "                                                 batch_size = hyper_batch_size, \n",
    "                                                 class_mode = 'categorical',\n",
    "                                                  # classes = target_mapper.values(),\n",
    "                                                 color_mode = hyper_mode,\n",
    "                                                 shuffle=True,\n",
    "                                                 seed = seed_value)\n",
    "\n",
    "test_generator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d24df85c-a7dc-484f-ad5b-15abfb537105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 1)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9a6bd587-62a8-4512-8a4b-7fedfcf3fffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "64cd389f-dee1-4a15-9e6c-d2b6021fe62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network!\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(hyper_dimension, hyper_dimension, hyper_channels)))\n",
    "\n",
    "# First convolutional layer with max pooling\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\", kernel_regularizer=l2(0.05), bias_regularizer=l2(0.05)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Second convolutional layer with max pooling\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\", kernel_regularizer=l2(0.05), bias_regularizer=l2(0.05)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\", kernel_regularizer=l2(0.05), bias_regularizer=l2(0.05)))\n",
    "model.add(Flatten())\n",
    "# Hidden layer with 500 nodes\n",
    "model.add(Dense(500, activation=\"relu\", kernel_regularizer=l2(0.05), bias_regularizer=l2(0.05)))\n",
    "\n",
    "# Output layer with 36 nodes (one for each possible letter/number we predict)\n",
    "model.add(Dense(26, activation=\"softmax\", kernel_regularizer=l2(0.05), bias_regularizer=l2(0.05)))\n",
    "\n",
    "# Ask Keras to build the TensorFlow model behind the scenes\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "13c468b5-9b7d-48ad-8787-cdbb3777426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ed2d7be0-c027-4bd6-8e4d-e1e412b2ef95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "65/65 - 318s - 5s/step - accuracy: 0.3006 - loss: 9.4715 - val_accuracy: 0.5152 - val_loss: 3.4034\n",
      "Epoch 2/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "65/65 - 125s - 2s/step - accuracy: 0.5798 - loss: 2.7592 - val_accuracy: 0.6244 - val_loss: 2.3454\n",
      "Epoch 4/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "65/65 - 122s - 2s/step - accuracy: 0.6417 - loss: 2.1412 - val_accuracy: 0.6378 - val_loss: 2.0280\n",
      "Epoch 6/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "65/65 - 123s - 2s/step - accuracy: 0.6700 - loss: 1.9186 - val_accuracy: 0.6826 - val_loss: 1.8415\n",
      "Epoch 8/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "65/65 - 121s - 2s/step - accuracy: 0.6934 - loss: 1.7777 - val_accuracy: 0.7108 - val_loss: 1.7075\n",
      "Epoch 10/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "65/65 - 122s - 2s/step - accuracy: 0.7279 - loss: 1.6344 - val_accuracy: 0.7211 - val_loss: 1.6518\n",
      "Epoch 12/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "65/65 - 121s - 2s/step - accuracy: 0.7425 - loss: 1.5863 - val_accuracy: 0.7494 - val_loss: 1.5641\n",
      "Epoch 14/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "65/65 - 122s - 2s/step - accuracy: 0.7623 - loss: 1.5156 - val_accuracy: 0.7637 - val_loss: 1.5035\n",
      "Epoch 16/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "65/65 - 122s - 2s/step - accuracy: 0.7655 - loss: 1.5004 - val_accuracy: 0.7828 - val_loss: 1.4613\n",
      "Epoch 18/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "65/65 - 124s - 2s/step - accuracy: 0.7822 - loss: 1.4499 - val_accuracy: 0.7937 - val_loss: 1.4223\n",
      "Epoch 20/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "65/65 - 121s - 2s/step - accuracy: 0.7885 - loss: 1.4205 - val_accuracy: 0.7900 - val_loss: 1.4392\n",
      "Epoch 22/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "65/65 - 121s - 2s/step - accuracy: 0.7913 - loss: 1.4067 - val_accuracy: 0.7517 - val_loss: 1.5155\n",
      "Epoch 24/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "65/65 - 121s - 2s/step - accuracy: 0.7976 - loss: 1.3907 - val_accuracy: 0.7971 - val_loss: 1.3834\n",
      "Epoch 26/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "65/65 - 126s - 2s/step - accuracy: 0.8037 - loss: 1.3729 - val_accuracy: 0.7966 - val_loss: 1.3895\n",
      "Epoch 28/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "65/65 - 127s - 2s/step - accuracy: 0.8112 - loss: 1.3426 - val_accuracy: 0.7953 - val_loss: 1.3866\n",
      "Epoch 30/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "65/65 - 128s - 2s/step - accuracy: 0.8039 - loss: 1.3744 - val_accuracy: 0.7907 - val_loss: 1.4218\n",
      "Epoch 32/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "65/65 - 128s - 2s/step - accuracy: 0.8135 - loss: 1.3477 - val_accuracy: 0.8032 - val_loss: 1.3747\n",
      "Epoch 34/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "65/65 - 126s - 2s/step - accuracy: 0.8136 - loss: 1.3534 - val_accuracy: 0.8014 - val_loss: 1.3757\n",
      "Epoch 36/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "65/65 - 130s - 2s/step - accuracy: 0.8141 - loss: 1.3467 - val_accuracy: 0.8204 - val_loss: 1.3099\n",
      "Epoch 38/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "65/65 - 131s - 2s/step - accuracy: 0.8161 - loss: 1.3267 - val_accuracy: 0.8032 - val_loss: 1.3639\n",
      "Epoch 40/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "65/65 - 126s - 2s/step - accuracy: 0.8162 - loss: 1.3294 - val_accuracy: 0.8014 - val_loss: 1.3712\n",
      "Epoch 42/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "65/65 - 126s - 2s/step - accuracy: 0.8157 - loss: 1.3383 - val_accuracy: 0.8239 - val_loss: 1.3274\n",
      "Epoch 44/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "65/65 - 128s - 2s/step - accuracy: 0.8161 - loss: 1.3242 - val_accuracy: 0.8092 - val_loss: 1.3563\n",
      "Epoch 46/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "65/65 - 129s - 2s/step - accuracy: 0.8136 - loss: 1.3549 - val_accuracy: 0.8250 - val_loss: 1.3183\n",
      "Epoch 48/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "65/65 - 125s - 2s/step - accuracy: 0.8205 - loss: 1.3171 - val_accuracy: 0.8197 - val_loss: 1.3177\n",
      "Epoch 50/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "65/65 - 127s - 2s/step - accuracy: 0.8206 - loss: 1.3054 - val_accuracy: 0.8174 - val_loss: 1.3213\n",
      "Epoch 52/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "65/65 - 131s - 2s/step - accuracy: 0.8179 - loss: 1.3188 - val_accuracy: 0.8206 - val_loss: 1.2925\n",
      "Epoch 54/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "65/65 - 128s - 2s/step - accuracy: 0.8200 - loss: 1.2908 - val_accuracy: 0.8177 - val_loss: 1.3187\n",
      "Epoch 56/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "65/65 - 127s - 2s/step - accuracy: 0.8224 - loss: 1.3030 - val_accuracy: 0.7974 - val_loss: 1.3641\n",
      "Epoch 58/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "65/65 - 126s - 2s/step - accuracy: 0.8186 - loss: 1.3037 - val_accuracy: 0.8013 - val_loss: 1.3358\n",
      "Epoch 60/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "65/65 - 130s - 2s/step - accuracy: 0.8166 - loss: 1.3073 - val_accuracy: 0.8090 - val_loss: 1.3213\n",
      "Epoch 62/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "65/65 - 131s - 2s/step - accuracy: 0.8221 - loss: 1.3078 - val_accuracy: 0.8176 - val_loss: 1.3129\n",
      "Epoch 64/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "65/65 - 125s - 2s/step - accuracy: 0.8197 - loss: 1.3021 - val_accuracy: 0.8008 - val_loss: 1.3511\n",
      "Epoch 66/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "65/65 - 126s - 2s/step - accuracy: 0.8200 - loss: 1.3006 - val_accuracy: 0.8203 - val_loss: 1.3007\n",
      "Epoch 68/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "65/65 - 125s - 2s/step - accuracy: 0.8180 - loss: 1.2937 - val_accuracy: 0.8122 - val_loss: 1.3122\n",
      "Epoch 70/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "65/65 - 125s - 2s/step - accuracy: 0.8184 - loss: 1.2935 - val_accuracy: 0.8196 - val_loss: 1.3055\n",
      "Epoch 72/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "65/65 - 125s - 2s/step - accuracy: 0.8219 - loss: 1.2819 - val_accuracy: 0.8148 - val_loss: 1.3251\n",
      "Epoch 74/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "65/65 - 130s - 2s/step - accuracy: 0.8179 - loss: 1.2833 - val_accuracy: 0.7672 - val_loss: 1.4075\n",
      "Epoch 76/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "65/65 - 127s - 2s/step - accuracy: 0.8162 - loss: 1.2919 - val_accuracy: 0.8028 - val_loss: 1.3407\n",
      "Epoch 78/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "65/65 - 125s - 2s/step - accuracy: 0.8161 - loss: 1.3242 - val_accuracy: 0.8229 - val_loss: 1.3264\n",
      "Epoch 80/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "65/65 - 126s - 2s/step - accuracy: 0.8178 - loss: 1.3085 - val_accuracy: 0.7743 - val_loss: 1.4504\n",
      "Epoch 82/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "65/65 - 125s - 2s/step - accuracy: 0.8154 - loss: 1.3164 - val_accuracy: 0.8040 - val_loss: 1.3370\n",
      "Epoch 84/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "65/65 - 125s - 2s/step - accuracy: 0.8184 - loss: 1.3084 - val_accuracy: 0.8154 - val_loss: 1.2939\n",
      "Epoch 86/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "65/65 - 126s - 2s/step - accuracy: 0.8156 - loss: 1.2942 - val_accuracy: 0.8079 - val_loss: 1.3103\n",
      "Epoch 88/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "65/65 - 127s - 2s/step - accuracy: 0.8142 - loss: 1.3037 - val_accuracy: 0.8203 - val_loss: 1.2974\n",
      "Epoch 90/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "65/65 - 128s - 2s/step - accuracy: 0.8141 - loss: 1.3332 - val_accuracy: 0.8193 - val_loss: 1.3551\n",
      "Epoch 92/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "65/65 - 126s - 2s/step - accuracy: 0.8155 - loss: 1.3087 - val_accuracy: 0.8185 - val_loss: 1.3092\n",
      "Epoch 94/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "65/65 - 125s - 2s/step - accuracy: 0.8100 - loss: 1.3269 - val_accuracy: 0.8080 - val_loss: 1.3055\n",
      "Epoch 96/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "65/65 - 126s - 2s/step - accuracy: 0.8096 - loss: 1.3426 - val_accuracy: 0.7849 - val_loss: 1.3990\n",
      "Epoch 98/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "65/65 - 125s - 2s/step - accuracy: 0.8065 - loss: 1.3647 - val_accuracy: 0.8184 - val_loss: 1.2914\n",
      "Epoch 100/100\n",
      "65/65 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch = len(train_generator),\n",
    "    epochs = hyper_epochs,\n",
    "    validation_data = test_generator,\n",
    "    validation_steps = len(test_generator),\n",
    "    verbose=2,\n",
    "    # callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e25af77-7734-4d6b-a93b-25776b9d5da6",
   "metadata": {},
   "source": [
    "# Save the model to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b245c878-8be6-4990-a538-457b3ee3d871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('cnn_captcha.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f682b3e8-a34e-4fce-8d38-e0d0aaa6d375",
   "metadata": {},
   "source": [
    "# Prediction of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6e555221-79a1-4bce-9c1d-736b8686b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_map = {}\n",
    "for index, value in enumerate(ALL_SYMBOLS):\n",
    "    back_map[str(index)] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c0adbe89-59b4-4392-954f-c9c8637c213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "399538cc-42fb-4995-ba72-f5dd4024ed40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'A',\n",
       " '1': 'B',\n",
       " '2': 'C',\n",
       " '3': 'D',\n",
       " '4': 'E',\n",
       " '5': 'F',\n",
       " '6': 'G',\n",
       " '7': 'H',\n",
       " '8': 'I',\n",
       " '9': 'J',\n",
       " '10': 'K',\n",
       " '11': 'L',\n",
       " '12': 'M',\n",
       " '13': 'N',\n",
       " '14': 'O',\n",
       " '15': 'P',\n",
       " '16': 'Q',\n",
       " '17': 'R',\n",
       " '18': 'S',\n",
       " '19': 'T',\n",
       " '20': 'U',\n",
       " '21': 'V',\n",
       " '22': 'W',\n",
       " '23': 'X',\n",
       " '24': 'Y',\n",
       " '25': 'Z'}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "aad5cea4-5238-4a1a-ad14-c0788e678077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">12,544,500</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">13,026</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)                 │      \u001b[38;5;34m12,544,500\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)                  │          \u001b[38;5;34m13,026\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,576,344</span> (47.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,576,344\u001b[0m (47.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,576,342</span> (47.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,576,342\u001b[0m (47.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model from the .h5 file\n",
    "m = load_model('cnn_captcha.h5')\n",
    "\n",
    "# Print the model summary\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ca115f05-0912-4dc0-b958-a2380088779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "\n",
    "    pathes = []\n",
    "    curr_symb = 0\n",
    "    img = cv.imread(\"test.png\")\n",
    "    \n",
    "    # convert to grayscale\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    # blur\n",
    "    blur = cv.GaussianBlur(gray, (0, 0), sigmaX=33, sigmaY=33)\n",
    "    # divide\n",
    "    divide = cv.divide(gray, blur, scale=255)\n",
    "    # otsu threshold\n",
    "    thresh = cv.threshold(divide, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)[1] # \n",
    "    # apply morphology\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (4, 4))\n",
    "    morph = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel)\n",
    "\n",
    "    threshold = 150\n",
    "    canny_output = cv.Canny(morph, threshold, threshold * 2)\n",
    "    canny_output_cp = canny_output.copy()\n",
    "    canny_output = cv.blur(canny_output, (3, 3))\n",
    "    \n",
    "    # cv.imshow(\"\", canny_output)\n",
    "    # cv.waitKey()\n",
    "    # cv.destroyAllWindows()\n",
    "    \n",
    "    contours, hierarchy = cv.findContours(canny_output, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    contours = [get_corners(i) for i in contours]\n",
    "    contours = filter_inner_contour(contours)\n",
    "    contours = sorted(contours, key=lambda x: get_square(*x), reverse=True)\n",
    "    contours = list(filter(lambda x: get_square(*x) > 400, contours))\n",
    "    if not contours:\n",
    "        return pathes\n",
    "    while len(contours) < 4:\n",
    "        contours = split_rectangles(contours)\n",
    "    contours = sorted(contours, key=lambda x: x[0][0])\n",
    "    contours = [expand_rectangle(i, 1.5) for i in contours]\n",
    "    \n",
    "    # symbols = re.search(r\"\\\\(\\w+)\\.\", all_captchas[idx]).group(1)\n",
    "    # drawing = np.zeros((canny_output.shape[0], canny_output.shape[1], 3), dtype=np.uint8)\n",
    "    for i in range(4):\n",
    "        color = (random.randint(0,256), random.randint(0,256), random.randint(0,256))\n",
    "        # morph = cv.rectangle(morph, contours[i][0], contours[i][1], color, 2)\n",
    "        # cv.drawContours(drawing, contours, i, color, 2, cv.LINE_8, hierarchy, 0)\n",
    "        # curr_path = os.path.join(os.getcwd(), str(target_mapper[symbols[i]]))\n",
    "        curr_path = os.path.join(os.getcwd(), \"{0:010d}.png\".format(curr_symb))\n",
    "        curr_symb += 1\n",
    "        crop_img = morph[contours[i][0][1]:contours[i][1][1], contours[i][0][0]:contours[i][1][0]]\n",
    "        # morph[contours[i][0][1]:contours[i][1][1], contours[i][0][0]:contours[i][1][0]]\n",
    "        cv.imwrite(curr_path, crop_img)\n",
    "        pathes.append(curr_path)\n",
    "\n",
    "    return pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c3a7e771-d75a-4fe5-b723-a75a26b018e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_captcha_text(length=4):\n",
    "\n",
    "    symbols_list = []\n",
    "    for _ in range(length):\n",
    "        symbols_list.append(random.choice(ALL_SYMBOLS))\n",
    "\n",
    "    return \"\".join(symbols_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "c736e3ae-819c-497a-9ea8-ee778b9fba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captcha.image import ImageCaptcha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338e9b68-f01e-4964-a1e7-75d52b98b7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "5793c629-4986-4c2d-af95-cc642d50ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test():\n",
    "    image = ImageCaptcha(width = 280, height = 90)\n",
    "    captcha_text = gen_captcha_text(length=4)\n",
    "    # generate the image of the given text\n",
    "    data = image.generate(captcha_text)  \n",
    "    # write the image on the given file and save it\n",
    "    image.write(captcha_text, f'test.png')\n",
    "\n",
    "    captcha_ls = []\n",
    "    for path in preprocess():\n",
    "        img = cv.imread(path)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Resize the image to the target input shape (e.g., 64x64 pixels)\n",
    "        target_size = (hyper_dimension, hyper_dimension)\n",
    "        img = cv.resize(img, target_size)\n",
    "    \n",
    "        # cv.imshow(\"\", img)\n",
    "        # cv.waitKey()\n",
    "        # cv.destroyAllWindows()\n",
    "        \n",
    "        # Convert the resized image to a NumPy array\n",
    "        img_array = img_to_array(img)\n",
    "        \n",
    "        # Expand the dimensions of the image array to match the expected input shape of the model\n",
    "        img_input = np.expand_dims(img_array, axis=0)\n",
    "        \n",
    "        # Normalize the image data to a range of [0, 1] (optional, depending on model requirements)\n",
    "        img_input = img_input / 255.0  # Assuming pixel values are in the range [0, 255]\n",
    "        predictions = m.predict(img_input, verbose=0)\n",
    "        predictions = predictions[0]\n",
    "    \n",
    "        captcha_ls.append(back_map[classes[predictions.argmax()]])\n",
    "        \n",
    "    result = \"\".join(captcha_ls)\n",
    "    print(f\"true_value: {captcha_text}\\tpredicted_value: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "2ebcf6ac-bab8-41a2-883e-862a0ca76275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_value: ENFB\tpredicted_value: ENFB\n",
      "true_value: ZMXI\tpredicted_value: ZMXI\n",
      "true_value: BHIR\tpredicted_value: BHTK\n",
      "true_value: KBRE\tpredicted_value: KBRE\n",
      "true_value: HIAX\tpredicted_value: HIAX\n",
      "true_value: OOTA\tpredicted_value: OOTA\n",
      "true_value: BEQD\tpredicted_value: BEQO\n",
      "true_value: SGKH\tpredicted_value: SGKH\n",
      "true_value: ZXMR\tpredicted_value: IXMR\n",
      "true_value: HUTD\tpredicted_value: HQTD\n",
      "true_value: BNAT\tpredicted_value: HVAT\n",
      "true_value: DELK\tpredicted_value: OELK\n",
      "true_value: UJPU\tpredicted_value: UJPU\n",
      "true_value: FJBJ\tpredicted_value: FJBJ\n",
      "true_value: WAQM\tpredicted_value: WAQM\n",
      "true_value: VIXP\tpredicted_value: VIXP\n",
      "true_value: LJLF\tpredicted_value: JJJF\n",
      "true_value: WVHZ\tpredicted_value: WVHZ\n",
      "true_value: FKBV\tpredicted_value: FKBV\n",
      "true_value: NTOP\tpredicted_value: NTOP\n",
      "true_value: BJPM\tpredicted_value: BJPM\n",
      "true_value: ZFSH\tpredicted_value: ZRSH\n",
      "true_value: TGMW\tpredicted_value: TGMW\n",
      "true_value: KAXZ\tpredicted_value: KAXZ\n",
      "true_value: XMOM\tpredicted_value: KMOM\n",
      "true_value: IHZZ\tpredicted_value: IHZZ\n",
      "true_value: NTBU\tpredicted_value: NTBU\n",
      "true_value: OOZL\tpredicted_value: OOZL\n",
      "true_value: IRUD\tpredicted_value: IRUO\n",
      "true_value: BMFJ\tpredicted_value: MEMC\n",
      "true_value: GLOL\tpredicted_value: GJDJ\n",
      "true_value: NTWQ\tpredicted_value: NTWQ\n",
      "true_value: YVDM\tpredicted_value: YVDM\n",
      "true_value: MOXX\tpredicted_value: MOXX\n",
      "true_value: HYLU\tpredicted_value: WNJU\n",
      "true_value: GTFS\tpredicted_value: GTFS\n",
      "true_value: JHSG\tpredicted_value: JTSG\n",
      "true_value: IMZG\tpredicted_value: TMZG\n",
      "true_value: JCQA\tpredicted_value: JCQA\n",
      "true_value: VNTL\tpredicted_value: VMGJ\n",
      "true_value: JXON\tpredicted_value: JNON\n",
      "true_value: NLEX\tpredicted_value: NLEX\n",
      "true_value: GQKM\tpredicted_value: GKKM\n",
      "true_value: RGNS\tpredicted_value: RGNS\n",
      "true_value: RTEW\tpredicted_value: RTEW\n",
      "true_value: NMNH\tpredicted_value: NMNH\n",
      "true_value: FUKE\tpredicted_value: FUKE\n",
      "true_value: UYPD\tpredicted_value: UYPO\n",
      "true_value: EVIT\tpredicted_value: EVTT\n",
      "true_value: NHTD\tpredicted_value: NHTO\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    run_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "added100-d8af-4648-998e-be278f575f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4420616378896656"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8154**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "98a51863-d3fa-41dd-8e60-61b644c0dc6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdf0943-3253-490b-b0c6-84ec22f93711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
